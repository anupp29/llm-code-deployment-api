# ğŸ¯ LLM Code Deployment API

**Production-ready API for automated code generation, GitHub deployment, and evaluation.**
## ğŸš€ **Live Demo**

- **API Endpoint**: `https://your-deployed-url.com/api-endpoint`
- **Health Check**: `https://your-deployed-url.com/health`
- **Documentation**: `https://your-deployed-url.com/docs`

## âœ¨ **Features**

- ğŸ¤– **AI-Powered Code Generation** using OpenAI GPT-4
- ğŸ™ **Automated GitHub Repository Creation** and deployment
- ğŸ“„ **GitHub Pages Integration** for instant hosting
- ğŸ”„ **Multi-Round Support** for iterative development
- ğŸ“Š **Comprehensive Evaluation System** with automated scoring
- ğŸ”’ **Secure Authentication** with secret validation
- âš¡ **Background Processing** for non-blocking operations

## ğŸ® **Quick Start**

### **1. Deploy Instantly**

Click the Railway button above or:

```bash
# Clone and deploy to Railway
git clone <your-repo>
cd llm-deployment-api
railway up
```

### **2. Set Environment Variables**

```bash
USER_SECRET="TDS DEDLY"
GITHUB_TOKEN="your_github_token"
GITHUB_USERNAME="your_username"
OPENAI_API_KEY="your_openai_key"
OPENAI_BASE_URL="https://aipipe.org/openai/v1"
```

### **3. Test the API**

```bash
curl -X POST https://your-app.railway.app/api-endpoint \
  -H "Content-Type: application/json" \
  -d '{
    "email": "student@example.com",
    "secret": "TDS DEDLY",
    "task": "demo-task",
    "round": 1,
    "nonce": "unique-id",
    "brief": "Create a Bootstrap dashboard",
    "checks": ["Has MIT license", "Professional README"],
    "evaluation_url": "https://httpbin.org/post"
  }'
```

## ğŸ“‹ **API Reference**

### **POST /api-endpoint**

Main endpoint for code generation and deployment requests.

**Request Body:**
```json
{
  "email": "student@example.com",
  "secret": "your_secret",
  "task": "unique-task-id",
  "round": 1,
  "nonce": "unique-nonce",
  "brief": "Detailed description of what to build",
  "checks": ["List of evaluation criteria"],
  "evaluation_url": "https://evaluation-server.com/notify",
  "attachments": [{"name": "file.csv", "url": "data:text/csv;base64,..."}]
}
```

**Response:**
```json
{
  "status": "accepted",
  "note": "processing round 1 started"
}
```

### **GET /health**

Health check endpoint with configuration status.

### **GET /**

API information and version.

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Student API   â”‚â”€â”€â”€â–¶â”‚   LLM Generator  â”‚â”€â”€â”€â–¶â”‚  GitHub Pages   â”‚
â”‚   (FastAPI)     â”‚    â”‚   (OpenAI GPT-4) â”‚    â”‚   (Deployment)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluation     â”‚    â”‚   Background     â”‚    â”‚   Notification  â”‚
â”‚   Server        â”‚    â”‚   Processing     â”‚    â”‚    System       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ **Local Development**

```bash
# Clone repository
git clone <your-repo>
cd llm-deployment-api

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your credentials

# Run locally
uvicorn app.main:app --reload
```

## ğŸ“Š **Monitoring & Analytics**

- **Health Monitoring**: Built-in health checks
- **Request Logging**: Comprehensive request/response logging
- **Error Tracking**: Detailed error reporting
- **Performance Metrics**: Response time and success rate tracking

## ğŸ”’ **Security**

- âœ… Secret-based authentication
- âœ… Input validation and sanitization
- âœ… Rate limiting ready
- âœ… No sensitive data in logs
- âœ… Secure environment variable handling

## ğŸ“ˆ **Production Features**

- âš¡ **Async Processing**: Non-blocking background tasks
- ğŸ”„ **Retry Logic**: Exponential backoff for external APIs
- ğŸ“ **Comprehensive Logging**: Detailed operation tracking
- ğŸ›¡ï¸ **Error Handling**: Graceful failure recovery
- ğŸ¯ **Health Checks**: Built-in monitoring endpoints

## ğŸ¤ **Contributing**

This is a production-ready implementation of the LLM Code Deployment project. The system handles:

1. **Code Generation**: AI-powered application creation
2. **GitHub Integration**: Automated repository and Pages deployment
3. **Evaluation Pipeline**: Comprehensive testing and scoring
4. **Multi-Round Support**: Iterative development workflow

## ğŸ“„ **License**

MIT License - see LICENSE file for details.

---

**ğŸš€ Ready for production deployment!** See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment instructions.


